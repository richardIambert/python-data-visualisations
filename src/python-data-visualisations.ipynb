{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdedb96-5067-46de-a0f3-db9c404f068e",
   "metadata": {},
   "source": [
    "# Creating Data Visualisations using Python\n",
    "\n",
    "Creating data visualisations in Python generally involves three stages, including:\n",
    "\n",
    "The three stages are:\n",
    "1. Loading the dataset.\n",
    "2. Identifying, cleaning, and shaping relevant data.\n",
    "3. Visually presenting these insights.\n",
    "\n",
    "> __Note__: We'll explore each of these stages, using a [Kickstarter Projects](https://www.kaggle.com/kemical/kickstarter-projects?select=ks-projects-201801.csv) dataset.\n",
    "\n",
    "## 1. Loading the dataset\n",
    "\n",
    "### What happens at this stage?\n",
    "\n",
    "This is the stage where we import our data into the python environment.\n",
    "\n",
    "### What are some of the common data sources used?\n",
    "\n",
    "We can load data stored in common file formats including, `.csv`, `.xlsx`, and `.json`. We can also load data from a database.\n",
    "\n",
    "### What python libraries can we use for this task?\n",
    "\n",
    "- [pandas]() - _pandas_ can read data from many file formats outputting a dataframe.\n",
    "- [openpyxl]() or [xlrd]() - _openpyxl_ and _xlrd_ are popular choices for loading excel files.\n",
    "- [sqlalchemy]() - _sqlalchemy_ is an object relational mapper (ORM) for python which can be used to access SQL databases and load data.\n",
    "\n",
    "## 2. Cleaning and Shaping the Dataset\n",
    "\n",
    "### What happens at this stage?\n",
    "\n",
    "At this stage, we identify the data that is relevant for the insights we wish to explore. From here, we ensure the data is accurate, complete, and in a format that’s ready for analysis or visualisation. This can include:\n",
    "\n",
    "1. Handling missing values (`df.dropna()`, `df.fillna()`)\n",
    "2. Renaming or selecting columns\n",
    "3. Changing data types (`df['date'] = pd.to_datetime(df['date'])`)\n",
    "4. Filtering or grouping data\n",
    "5. Merging or joining datasets\n",
    "\n",
    "### What are some of the common tools and libraries used at this stage?\n",
    "\n",
    "- [pandas]() - _pandas_ for data manipulation\n",
    "- [numpy]() - _numpy_ for numerical operations\n",
    "\n",
    "## 3. Visually presenting these insights\n",
    "\n",
    "### What happens at this stage?\n",
    "\n",
    "This is where we use our prepared data to create visualisations including: charts, graphs, and other visual representations of the data.\n",
    "\n",
    "### What are some of the popular libraries used for this task?\n",
    "\n",
    "- [matplotlib]() – _matplotlib_ is a low-level plotting library that offers a high degree of control but can be more verbose.\n",
    "- [seaborn]() – _seaborn_ provides statistical plots built on top of matplotlib and is considered easier to use but with less control.\n",
    "- [plotly]() – _plotly_ produces interactive visualisations\n",
    "- [pandas]() -  built-in plotting (df.plot())\n",
    "\n",
    "Example using Seaborn:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x='category', y='value', data=df)\n",
    "plt.title('Value by Category')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
